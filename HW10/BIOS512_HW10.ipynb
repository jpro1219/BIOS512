{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d684172-4b94-42cf-bda2-e11952420d86",
      "metadata": {
        "id": "4d684172-4b94-42cf-bda2-e11952420d86"
      },
      "source": [
        "# Homework 10\n",
        "#### Course Notes\n",
        "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
        "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
        "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d839a5ba-62f4-4699-baea-018afda70786",
      "metadata": {
        "id": "d839a5ba-62f4-4699-baea-018afda70786"
      },
      "source": [
        "## Question 1\n",
        "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(httr)\n",
        "library(tokenizers)\n",
        "library(stringr)"
      ],
      "metadata": {
        "id": "6hiw66cWs7Bn"
      },
      "id": "6hiw66cWs7Bn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
      "metadata": {
        "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49"
      },
      "source": [
        "#### a) Make a function to tokenize the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_text <- function(text) {\n",
        "    tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n",
        "}"
      ],
      "metadata": {
        "id": "aFNk777-tQx6"
      },
      "id": "aFNk777-tQx6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "86145513-294b-4894-a02c-8ae60e2c616e",
      "metadata": {
        "id": "86145513-294b-4894-a02c-8ae60e2c616e"
      },
      "source": [
        "#### b) Make a function generate keys for ngrams."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key_from <- function(ngram, sep = \"\\x1f\") {\n",
        "    paste(ngram, collapse=sep)\n",
        "}"
      ],
      "metadata": {
        "id": "Vt5L5AmZukuJ"
      },
      "id": "Vt5L5AmZukuJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "52988c2c-b230-467f-b519-72bc85b93b43",
      "metadata": {
        "id": "52988c2c-b230-467f-b519-72bc85b93b43"
      },
      "source": [
        "#### c) Make a function to build an ngram table."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
        "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
        "    tbl <- new.env(parent = emptyenv())\n",
        "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
        "        ngram <- tokens[i:(i + n - 2L)]\n",
        "        next_word <- tokens[i + n - 1L]\n",
        "        key <- paste(ngram, collapse = sep)\n",
        "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "        if (next_word %in% names(counts)) {\n",
        "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
        "        } else {\n",
        "            counts[[next_word]] <- 1L\n",
        "        }\n",
        "        tbl[[key]] <- counts\n",
        "    }\n",
        "    tbl\n",
        "}"
      ],
      "metadata": {
        "id": "H9A_3qOquzEE"
      },
      "id": "H9A_3qOquzEE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1ca6db37-abce-4705-9784-e1b898174f00",
      "metadata": {
        "id": "1ca6db37-abce-4705-9784-e1b898174f00"
      },
      "source": [
        "#### d) Function to digest the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digest_text <- function(text, n) {\n",
        "    tokens <- tokenize_text(text)\n",
        "    build_ngram_table(tokens, n)\n",
        "}"
      ],
      "metadata": {
        "id": "6i0oy-tPu-SO"
      },
      "id": "6i0oy-tPu-SO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
      "metadata": {
        "id": "53fff313-0f13-479b-94df-7588c19fdd3d"
      },
      "source": [
        "#### e) Function to digest the url."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digest_url <- function(url, n) {\n",
        "    res <- httr::GET(url)\n",
        "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
        "    digest_text(txt,n)\n",
        "}"
      ],
      "metadata": {
        "id": "Sr_DcaRevAx2"
      },
      "id": "Sr_DcaRevAx2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
      "metadata": {
        "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a"
      },
      "source": [
        "#### f) Function that gives random start."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_start <- function(tbl, sep = \"\\x1f\") {\n",
        "    keys <- ls(envir = tbl, all.names=TRUE)\n",
        "    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n",
        "    picked <- sample(keys, 1)\n",
        "    strsplit(picked, sep, fixed=TRUE)[[1]]\n",
        "}"
      ],
      "metadata": {
        "id": "ZrkzOlG3vDjd"
      },
      "id": "ZrkzOlG3vDjd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
      "metadata": {
        "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f"
      },
      "source": [
        "#### g) Function to predict the next word."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
        "    key <- paste(ngram, collapse = sep)\n",
        "    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "    if (length(counts) == 0) return(NA_character_)\n",
        "    sample(names(counts), size=1, prob=as.numeric(counts))\n",
        "}"
      ],
      "metadata": {
        "id": "2_e1-5cTvFul"
      },
      "id": "2_e1-5cTvFul",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "347f4002-4932-42c4-a4af-8689293a5857",
      "metadata": {
        "id": "347f4002-4932-42c4-a4af-8689293a5857"
      },
      "source": [
        "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_ngram_generator <- function(tbl, n, start, sep = \"\\x1f\") {\n",
        "    force(tbl); n <- as.integer(n); force(sep)\n",
        "    function(start_words = start, length = 10L) {\n",
        "        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n",
        "            start_words <- random_start(tbl, sep=sep)\n",
        "        }\n",
        "        word_sequence <- start_words\n",
        "        for (i in seq_len(max(0L, length - length(start_words)))) {\n",
        "            ngram <- tail(word_sequence, n - 1L)\n",
        "            next_word <- predict_next_word(tbl, ngram, sep=sep)\n",
        "            if (is.na(next_word)) break\n",
        "            word_sequence <- c(word_sequence, next_word)\n",
        "        }\n",
        "        paste(word_sequence, collapse= \" \")\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "ow1b30EtvIBJ"
      },
      "id": "ow1b30EtvIBJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
      "metadata": {
        "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554"
      },
      "source": [
        "## Question 2\n",
        "#### For this question, set `seed=2025`.\n",
        "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2025)\n",
        "\n",
        "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\" # Text file of Grimm's Fairy Tales\n",
        "tbl <- digest_url(url, n=3)\n",
        "gen <- make_ngram_generator(tbl, n=3, \"the king\")\n",
        "print(gen(length=15))\n",
        "\n",
        "gen1 <- make_ngram_generator(tbl, n=3, NULL)\n",
        "print(gen1(length=15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUyDjSB9vRic",
        "outputId": "6a20617a-8d61-4d13-8f79-6627a2fc7525"
      },
      "id": "GUyDjSB9vRic",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"spread the jam over it spread its wings and crying here comes our hobblety jib\"\n",
            "[1] \"of 20 of the castle where anyone could be when tom had slipped off into\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
      "metadata": {
        "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc"
      },
      "source": [
        "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url2 <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\" # Text file of Ancient Armour and Weapons in Europe\n",
        "tbl2 <- digest_url(url2, n=3)\n",
        "gen2 <- make_ngram_generator(tbl2, n=3, \"the king\")\n",
        "print(gen2(length=15))\n",
        "\n",
        "gen3 <- make_ngram_generator(tbl2, n=3, NULL)\n",
        "print(gen3(length=15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ckAJ5B8xDhm",
        "outputId": "809583ab-45d8-460e-9fbe-f87b6879a5df"
      },
      "id": "0ckAJ5B8xDhm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"free stone of a real dagger which is commonly called the quintain and the curiously\"\n",
            "[1] \"and ecgum in this country and commonly attributed to ancient heroes had an especial notice\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
      "metadata": {
        "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc"
      },
      "source": [
        "#### c) Explain in 1-2 sentences the difference in content generated from each source."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At a basic level, the content seems to differ in tone. The Grimm text sounds more whimsicle and fantastical while the weapons source has a much more explanatory tone and speaks about weaponry."
      ],
      "metadata": {
        "id": "atIxQvC9xyQh"
      },
      "id": "atIxQvC9xyQh"
    },
    {
      "cell_type": "markdown",
      "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
      "metadata": {
        "id": "56e45972-f441-4d07-9073-fcddd6146cbd"
      },
      "source": [
        "## Question 3\n",
        "#### a) What is a language learning model?\n",
        "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A language model predicts the probability of a sequence of words based on context of several input words."
      ],
      "metadata": {
        "id": "3-SoLkCvyJA1"
      },
      "id": "3-SoLkCvyJA1"
    },
    {
      "cell_type": "markdown",
      "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
      "metadata": {
        "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8"
      },
      "source": [
        "## Question 4\n",
        "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
        "| Term | Meaning |  \n",
        "|------|---------|\n",
        "| **Shell** | The program that allows you to interact with the OS |\n",
        "| **Terminal emulator** | The place where the shell sits |\n",
        "| **Process** | Something your computer is running |\n",
        "| **Signal** | What is sent to processes to tell them to do something |\n",
        "| **Standard input** | Read characters from the input |\n",
        "| **Standard output** | Write characters to the output |\n",
        "| **Command line argument** | What is passed to a process when started |\n",
        "| **The environment** | What is available to a process while it is running |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
      "metadata": {
        "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2"
      },
      "source": [
        "## Question 5\n",
        "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
        "#### a) What are the programs?\n",
        "#### b) Explain what this command is doing, part by part."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find, xargs, and grep\n",
        "This command is searching for files with names ending in .R, then passing these file names and constructs command lines with them as argument. Then, grep reads these R files for the string read.csv"
      ],
      "metadata": {
        "id": "9hGyKmcMRMpG"
      },
      "id": "9hGyKmcMRMpG"
    },
    {
      "cell_type": "markdown",
      "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
      "metadata": {
        "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095"
      },
      "source": [
        "## Question 6\n",
        "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions.\n",
        "#### a) Show the response when you run `docker run hello-world`.\n",
        "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
        "#### c) How do you log in to the RStudio server?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xsq4AMNZYXDk"
      },
      "id": "xsq4AMNZYXDk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Hello from Docker!\n",
        "This message shows that your installation appears to be working correctly.\n",
        "\n",
        "To generate this message, Docker took the following steps:\n",
        " 1. The Docker client contacted the Docker daemon.\n",
        " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
        "    (amd64)\n",
        " 3. The Docker daemon created a new container from that image which runs the\n",
        "    executable that produces the output you are currently reading.\n",
        " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
        "    to your terminal.\n",
        "\n",
        "To try something more ambitious, you can run an Ubuntu container with:\n",
        " $ docker run -it ubuntu bash\n",
        "\n",
        "Share images, automate workflows, and more with a free Docker ID:\n",
        " https://hub.docker.com/\n",
        "\n",
        "For more examples and ideas, visit:\n",
        " https://docs.docker.com/get-started/"
      ],
      "metadata": {
        "id": "9QQ_uhU-RnQY"
      },
      "id": "9QQ_uhU-RnQY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "docker run -d -p 8787:8787 -e PASSWORD=yourpassword -v \"${PWD}:/home/rstudio\" rocker/rstudio\n",
        "\n",
        "Unable to find image 'rocker/rstudio:latest' locally\n",
        "latest: Pulling from rocker/rstudio\n",
        "191985778909: Pull complete\n",
        "08e74fd5985d: Pull complete\n",
        "5d246ec925db: Pull complete\n",
        "664fb1818bbb: Pull complete\n",
        "971ba7cf0d8a: Pull complete\n",
        "3c7cdccc4be7: Pull complete\n",
        "3665120d345d: Pull complete\n",
        "62f215ca34c6: Pull complete\n",
        "39038e16d1ba: Pull complete\n",
        "999e4b8f7ed8: Pull complete\n",
        "2a63ed8b2250: Pull complete\n",
        "9c1a4a0706b7: Pull complete\n",
        "4b3ffd8ccb52: Pull complete\n",
        "2c9ba66d5dbe: Pull complete\n",
        "e4b9e87bb831: Pull complete\n",
        "b71e78fefbbb: Pull complete\n",
        "890065c4c99d: Pull complete\n",
        "d923cf803a12: Pull complete\n",
        "Digest: sha256:9f85211a666fb426081a6f5a01f9f9f51655262258419fa21e0ce38a5afc78d8\n",
        "Status: Downloaded newer image for rocker/rstudio:latest\n",
        "00990d243020c90b96bb6d2d59cf71c49931e5639abed0ac158d30e92c2e79f2"
      ],
      "metadata": {
        "id": "xXeH8VaQXnjL"
      },
      "id": "xXeH8VaQXnjL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "http://localhost:8787/ and then type in the rstudio for username and yourpassword for password (which I previously set)"
      ],
      "metadata": {
        "id": "4LyuVQI8YrT6"
      },
      "id": "4LyuVQI8YrT6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.3.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}